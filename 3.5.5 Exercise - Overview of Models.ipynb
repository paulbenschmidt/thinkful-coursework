{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: what model can answer this question?\n",
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.**\n",
    "\n",
    "I would probably use a simple Linear Regression since the target is continuous (if it was binary, we could use Logistic Regression for probabilites of two outcomes).\n",
    "\n",
    "2. **You have more features (columns) than rows in your dataset.**\n",
    "\n",
    "I would probably choose Lasso Regression (which has the option of nulling out features depending on their coefficients, unlike Ridge Regression) in order to speed up the model by only using the features more valuable than the pre-determined threshold. Or I would use a Random Forest Classifier but limit the features to the most valuable according to '.featureimportance_'.\n",
    "\n",
    "3. **Identify the most important characteristic predicting likelihood of being jailed before age 20.**\n",
    "\n",
    "I would either use a combination of Decision Trees/Random Forest Classifier and see the featureimportance_ aspect for most valuable features in identifying whether or not someone would be jailed. Or I would normalize the data and use a Logistic Regression and observe the coefficients.\n",
    "\n",
    "4. **Implement a filter to “highlight” emails that might be important to the recipient**\n",
    "\n",
    "Either a Decision Tree or Random Forest Classifier.\n",
    "\n",
    "5. **You have 1000+ features.**\n",
    "\n",
    "I would probably choose Lasso Regression (which has the option of nulling out features depending on their coefficients, unlike Ridge Regression) in order to speed up the model by only using the features more valuable than the pre-determined threshold. Or I would use a Random Forest Classifier but limit the features to the most valuable according to '.featureimportance_'.\n",
    "\n",
    "6. **Predict whether someone who adds items to their cart on a website will purchase the items.**\n",
    "\n",
    "Logistic Regression to determine likelihood.\n",
    "\n",
    "7. **Your dataset dimensions are 982400 x 500**\n",
    "\n",
    "I would use a simpler, faster model (like Linear Regression or KNN Regression) and try and narrow down the feature set to most important features.\n",
    "\n",
    "8. **Identify faces in an image.**\n",
    "\n",
    "SVM as Classifier.\n",
    "\n",
    "9. **Predict which of three flavors of ice cream will be most popular with boys vs girls.**\n",
    "\n",
    "I would use a KNN Classifier or SVC because this would easily show clusters of preferences and distinguish between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of models:\n",
    "* Regression\n",
    "    * Simple Linear Regression (OLS): linear_model.LinearRegression()\n",
    "    * KNN Regression: neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "    * Logistic Regression: LogisticRegression(C=1e9) (*a quasi-classifier that predicts probability of two events*)\n",
    "    * Ridge Regression: linear_model.Ridge(alpha=10, fit_intercept=False)\n",
    "    * Lasso Regression: linear_model.Lasso(alpha=.35)\n",
    "    * Support Vector Regressor: SVR()\n",
    "\n",
    "* Classification\n",
    "    * KNN Classifier: KNeighborsClassifier(n_neighbors=5)\n",
    "    * Decision Tree: tree.DecisionTreeClassifier(criterion='entropy', max_features=1,max_depth=4)\n",
    "    * Random Forest: ensemble.RandomForestClassifier()\n",
    "    * Support Vector Classifier: SVC(kernel = 'linear')\n",
    "    * Gradient Boosting Classifier: ensemble.GradientBoostingClassifier(**params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
